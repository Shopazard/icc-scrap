{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-01T06:16:16.755942Z","iopub.status.busy":"2024-01-01T06:16:16.755573Z","iopub.status.idle":"2024-01-01T06:16:17.146460Z","shell.execute_reply":"2024-01-01T06:16:17.145445Z","shell.execute_reply.started":"2024-01-01T06:16:16.755916Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.148970Z","iopub.status.busy":"2024-01-01T06:16:17.148540Z","iopub.status.idle":"2024-01-01T06:16:17.188312Z","shell.execute_reply":"2024-01-01T06:16:17.187103Z","shell.execute_reply.started":"2024-01-01T06:16:17.148942Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(982, 11)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# data = pd.read_csv('/kaggle/input/icc-2000-to-9000-new/icc_2000_to_9000.csv')\n","data = pd.read_csv('/kaggle/input/icc-2000-to-3000/icc_2000_to_3000.csv')\n","data.shape"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.189700Z","iopub.status.busy":"2024-01-01T06:16:17.189405Z","iopub.status.idle":"2024-01-01T06:16:17.347380Z","shell.execute_reply":"2024-01-01T06:16:17.346412Z","shell.execute_reply.started":"2024-01-01T06:16:17.189663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7458 7458 7458\n","Success for name is 82.97655453618756 good 814 bad 167 total 981\n","Success for complaining_party is 95.61671763506627 good 938 bad 43 total 981\n","Success for defending_party is 87.86952089704383 good 862 bad 119 total 981\n","Success for judges is 100.0 good 977 bad 0 total 977\n","Success for court is 97.65545361875637 good 958 bad 23 total 981\n","Success for year is 98.77675840978594 good 969 bad 12 total 981\n","Success for month is 99.18450560652396 good 973 bad 8 total 981\n","Success for day is 98.57288481141691 good 967 bad 14 total 981\n"]}],"source":["extract = data.iloc[1:,:]\n","\n","failed = []\n","questions = ['name', 'complaining_party', 'defending_party', 'judges','court','end_date']\n","context_df = []\n","answers_df = []\n","questions_df = []\n","for index,row in extract.iterrows():\n","    current_row = []\n","    context = row.text.replace('_:::_',' ')\n","#     print(index,context)\n","    for i,question in enumerate(questions):\n","        \n","        if question == 'end_date':\n","            answer = str(row[question]).strip()\n","            try:\n","                year,month,day = answer.split(\"-\")\n","            except:\n","                print(answer)\n","                continue\n","            if month[0] == '0': month = month[1]\n","            if day[0] == '0': day = day[1]\n","            year_start_idx = context.find(year)\n","            year_end_idx = context.find(year) + len(year)\n","            if year == context[int(year_start_idx):int(year_end_idx)]:\n","                context_df.append(str(context))\n","                answers_df.append({'text': year,'s':year_start_idx,'e': year_end_idx})\n","                questions_df.append('year')\n","            else: failed.append('year')\n","#             print(\"year\",year_start_idx, year == context[int(year_start_idx):int(year_end_idx)])\n","            month_start_idx = context.find(month)\n","            month_end_idx = context.find(month) + len(month)\n","            if month == context[int(month_start_idx):int(month_end_idx)]:\n","                context_df.append(str(context))\n","                answers_df.append({'text': month,'s':month_start_idx,'e': month_end_idx})\n","                questions_df.append('month')\n","            else: failed.append('month')\n","#             print(\"month\",month_start_idx, month == context[int(month_start_idx):int(month_end_idx)])\n","            day_start_idx = context.find(day)\n","            day_end_idx = context.find(day) + len(day)\n","            if day == context[int(day_start_idx):int(day_end_idx)]:\n","                context_df.append(str(context))\n","                answers_df.append({'text': day,'s':day_start_idx,'e': day_end_idx})\n","                questions_df.append('day')\n","            else: failed.append('day')\n","#             print(\"day\",day_start_idx, day == context[int(day_start_idx):int(day_end_idx)])\n","        elif question == 'judges':\n","            lowest_index = 9999\n","            highest_index = 0\n","            judges = str(row[question]).replace(\",\",\"\").replace(\"|\",\" \")\n","            for judge in judges.split(\" \"):\n","                if not judge: continue\n","                judge = judge.strip()\n","                dex = context.find(judge)\n","                ldex = context.rfind(judge)\n","                if dex != -1:\n","                    lowest_index = dex if dex < lowest_index else lowest_index\n","                    highest_index = ldex + len(judge) if ldex > highest_index else highest_index\n","            if lowest_index == 9999 and highest_index == 0: continue\n","            start_idx = lowest_index\n","            end_idx = highest_index\n","#             print(question,start_idx, end_idx, context[int(start_idx):int(end_idx)])\n","#             if day == context[int(day_start_idx):int(day_end_idx)]:\n","            context_df.append(str(context))\n","            answers_df.append({'text': context[int(start_idx):int(end_idx)],'s':start_idx,'e': end_idx})\n","            questions_df.append(str(question))\n","#             else: failed.append(question)\n","            \n","        else:\n","            answer = str(row[question]).strip()\n","            start_idx = context.find(answer)\n","            end_idx = start_idx + len(answer)\n","            if answer == context[int(start_idx):int(end_idx)]:\n","                context_df.append(str(context))\n","                answers_df.append({'text': answer,'s':start_idx,'e': end_idx})\n","                questions_df.append(str(question))\n","            else: failed.append(question)\n","#             print(question,start_idx, answer == context[int(start_idx):int(end_idx)])\n","        \n","\n","    \n","\n","print(len(context_df), len(answers_df), len(questions_df))\n","questions.remove('end_date')\n","questions.append('year')\n","questions.append('month')\n","questions.append('day')\n","for q in questions:\n","    sc = questions_df.count(q)\n","    fc = failed.count(q)\n","    total = sc+ fc\n","    print(f'Success for {q} is {sc/total *100} good {sc} bad {fc} total {total}')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.349069Z","iopub.status.busy":"2024-01-01T06:16:17.348712Z","iopub.status.idle":"2024-01-01T06:16:17.354908Z","shell.execute_reply":"2024-01-01T06:16:17.353944Z","shell.execute_reply.started":"2024-01-01T06:16:17.349036Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["AIR 1950 MADHYA BHARAT 39 MADHYA BHARAT HIGH COURT  REGE   J.  Second Appeal No.227 of 1948  D/- 9 - 4 - 1949  Jugrajsa Chunilalsa Appellants v. Umrao Singh Sikdarsingh and others Respondents  Transfer of Property Act (4 of 1882)  S.108(h)  S.108(o) - Trees planted by tenant - Right to.  Samvatsar - for Appellant. VIPIN SANGHI - for Respondents.  Appeal Allowed .  {'text': 'Jugrajsa Chunilalsa Appellants v. Umrao Singh Sikdarsingh and others', 's': 111, 'e': 179} name\n"]}],"source":["print(context_df[0],answers_df[0],questions_df[0])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.358385Z","iopub.status.busy":"2024-01-01T06:16:17.358102Z","iopub.status.idle":"2024-01-01T06:16:17.868575Z","shell.execute_reply":"2024-01-01T06:16:17.867575Z","shell.execute_reply.started":"2024-01-01T06:16:17.358361Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["5966 1492 5966 1492 5966 1492\n"]}],"source":["from sklearn.model_selection import train_test_split\n","train_contexts, val_contexts, train_questions, val_questions, train_answers, val_answers = train_test_split(context_df, questions_df, answers_df, random_state=3, test_size=0.2)\n","print(len(train_contexts), len(val_contexts), len(train_questions), len(val_questions), len(train_answers), len(val_answers))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.870290Z","iopub.status.busy":"2024-01-01T06:16:17.869919Z","iopub.status.idle":"2024-01-01T06:16:17.876053Z","shell.execute_reply":"2024-01-01T06:16:17.875067Z","shell.execute_reply.started":"2024-01-01T06:16:17.870254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["AIR 1951 CALCUTTA 418 CALCUTTA HIGH COURT  DAS GUPTA   J. and P. N. MOOKERJEE   J.  Criminal Revn. No. 591 of 1950  D/- 5 - 1 - 1951  Bepin Behari Maity - Complainant - Petnr v. Paban Sardar and other Accused Opposite Party  Criminal P.C. (5 of 1898)  S.256  S.258  S.439 - Duty of Magistrate u/S.256 - Non-compliance with - Order of acquittal - Legality.  Anno. Cr. P. C.  S. 256  N. 4  5; S. 258  N. 4; S. 439  N. 12.  Nalin Chandra Banerjee for J.M. Banerjee - for Petnr.; Nalini Kumar Mukherjee - for Opposite Party.  Retrial Ordered .  {'text': 'DAS GUPTA   J. and P. N. MOOKERJEE   J.  Criminal Revn. No. 591 of 1950  D/- 5 - 1 - 1951  Bepin Behari Maity - Complainant - Petnr v. Paban Sardar and other Accused Opposite Party  Criminal P.C. (5 of 1898)  S.256  S.258  S.439 - Duty of Magistrate u/S.256 - Non-compliance with - Order of acquittal - Legality.  Anno. Cr. P. C.  S. 256  N. 4  5; S. 258  N. 4; S. 439  N. 12.  Nalin Chandra Banerjee for J.', 's': 43, 'e': 450} judges\n"]}],"source":["print(val_contexts[0],val_answers[0],val_questions[0])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:17.877607Z","iopub.status.busy":"2024-01-01T06:16:17.877319Z","iopub.status.idle":"2024-01-01T06:16:26.370827Z","shell.execute_reply":"2024-01-01T06:16:26.370009Z","shell.execute_reply.started":"2024-01-01T06:16:17.877582Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f133de0c1bcb406e8651104b3c4b2524","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2146f7d2fa84bc6ba1ae6b8f015a4e1","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3cfc25de20a4ef981bb86c03aa8f0db","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e604d21570a40a5a240c69fb73fca4c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n","train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n","val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:26.372489Z","iopub.status.busy":"2024-01-01T06:16:26.372052Z","iopub.status.idle":"2024-01-01T06:16:26.407981Z","shell.execute_reply":"2024-01-01T06:16:26.407024Z","shell.execute_reply.started":"2024-01-01T06:16:26.372462Z"},"trusted":true},"outputs":[],"source":["def add_token_positions(encodings, answers):\n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(answers)):\n","        start_positions.append(encodings.char_to_token(i, answers[i]['s']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['e'] - 1))\n","        # if None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        if end_positions[-1] is None:\n","            end_positions[-1] = tokenizer.model_max_length\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","\n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(val_encodings, val_answers)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:26.409834Z","iopub.status.busy":"2024-01-01T06:16:26.409195Z","iopub.status.idle":"2024-01-01T06:16:56.159333Z","shell.execute_reply":"2024-01-01T06:16:56.158285Z","shell.execute_reply.started":"2024-01-01T06:16:26.409806Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((\n","    {key: train_encodings[key] for key in ['input_ids', 'attention_mask']},\n","    {key: train_encodings[key] for key in ['start_positions', 'end_positions']}\n","))\n","val_dataset = tf.data.Dataset.from_tensor_slices((\n","    {key: val_encodings[key] for key in ['input_ids', 'attention_mask']},\n","    {key: val_encodings[key] for key in ['start_positions', 'end_positions']}\n",")) "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:16:56.161508Z","iopub.status.busy":"2024-01-01T06:16:56.160787Z","iopub.status.idle":"2024-01-01T06:17:00.837710Z","shell.execute_reply":"2024-01-01T06:17:00.836702Z","shell.execute_reply.started":"2024-01-01T06:16:56.161470Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaaef30e0eb642ce9712cc3a6d695590","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"974edcccd9924f08af014c70a575b0f9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights or buffers of the TF 2.0 model TFDistilBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import TFDistilBertForQuestionAnswering\n","model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:17:00.839326Z","iopub.status.busy":"2024-01-01T06:17:00.839042Z","iopub.status.idle":"2024-01-01T06:21:46.483481Z","shell.execute_reply":"2024-01-01T06:21:46.482477Z","shell.execute_reply.started":"2024-01-01T06:17:00.839301Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","373/373 [==============================] - 161s 349ms/step - loss: 6.0744 - output_1_loss: 2.8492 - output_2_loss: 3.2253 - output_1_accuracy: 0.1780 - output_2_accuracy: 0.1353\n","Epoch 2/2\n","373/373 [==============================] - 124s 333ms/step - loss: 2.3825 - output_1_loss: 0.9964 - output_2_loss: 1.3861 - output_1_accuracy: 0.6559 - output_2_accuracy: 0.5575\n"]}],"source":["# Keras will expect a tuple when dealing with labels\n","train_dataset = train_dataset.map(lambda x, y: (x, (y['start_positions'], y['end_positions'])))\n","# Keras will assign a separate loss for each output and add them together. So we'll just use the standard CE loss\n","# instead of using the built-in model.compute_loss, which expects a dict of outputs and averages the two terms.\n","# Note that this means the loss will be 2x of when using TFTrainer since we're adding instead of averaging them.\n","# detect and init the TPU\n","# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","\n","# instantiate a distribution strategy\n","# tf.tpu.experimental.initialize_tpu_system(tpu)\n","# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n","\n","# with tpu_strategy.scope():\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.distilbert.return_dict = False # if using 🤗 Transformers >3.02, make sure outputs are tuples\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) # can also use any keras loss fn\n","    \n","records = model.fit(train_dataset.shuffle(1000).batch(16), epochs=2, batch_size=16)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:21:46.485719Z","iopub.status.busy":"2024-01-01T06:21:46.484955Z","iopub.status.idle":"2024-01-01T06:22:05.833117Z","shell.execute_reply":"2024-01-01T06:22:05.832036Z","shell.execute_reply.started":"2024-01-01T06:21:46.485657Z"},"trusted":true},"outputs":[],"source":["model.save('basic2e')"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:22:05.835901Z","iopub.status.busy":"2024-01-01T06:22:05.835561Z","iopub.status.idle":"2024-01-01T06:22:05.842559Z","shell.execute_reply":"2024-01-01T06:22:05.841606Z","shell.execute_reply.started":"2024-01-01T06:22:05.835874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 19016, 2069, 3280, 8784, 12674, 16830, 9159, 3746, 1604, 8784, 12674, 16830, 9159, 145, 23413, 3048, 18732, 19556, 1942, 141, 10719, 144, 18124, 9159, 147, 119, 1105, 153, 119, 151, 119, 150, 2346, 22027, 9637, 4538, 27073, 147, 119, 10382, 6750, 1179, 119, 1302, 119, 4589, 1475, 1104, 3067, 141, 120, 118, 126, 118, 122, 118, 3280, 4108, 6709, 4108, 16234, 17551, 2340, 118, 3291, 8223, 15858, 2861, 118, 25993, 1179, 1197, 191, 119, 19585, 7167, 17784, 18484, 1197, 1105, 1168, 138, 19515, 11031, 9126, 5674, 13068, 1786, 10382, 153, 119, 140, 119, 113, 126, 1104, 5381, 114, 156, 119, 18440, 156, 119, 27434, 156, 119, 3887, 1580, 118, 21134, 1104, 7085, 25019, 18775, 190, 120, 156, 119, 18440, 118, 7922, 118, 14037, 1114, 118, 2864, 1104, 170, 1665, 18276, 5100, 1233, 118, 10800, 1785, 119, 5083, 1186, 119, 140, 1197, 119, 153, 119, 140, 119, 156, 119, 18440, 151, 119, 125, 126, 132, 156, 119, 27434, 151, 119, 125, 132, 156, 119, 3887, 1580, 151, 119, 1367, 119, 11896, 2836, 17595, 18393, 21186, 1111, 147, 119, 150, 119, 18393, 21186, 118, 1111, 25993, 1179, 1197, 119, 132, 11896, 21472, 9392, 19569, 9862, 21186, 118, 1111, 9126, 5674, 13068, 1786, 119, 11336, 19091, 1348, 2864, 1174, 119, 102, 1271, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["context_test = [\"AIR 1951 CALCUTTA 418 CALCUTTA HIGH COURT  DAS GUPTA   J. and P. N. MOOKERJEE   J.  Criminal Revn. No. 591 of 1950  D/- 5 - 1 - 1951  Bepin Behari Maity - Complainant - Petnr v. Paban Sardar and other Accused Opposite Party  Criminal P.C. (5 of 1898)  S.256  S.258  S.439 - Duty of Magistrate u/S.256 - Non-compliance with - Order of acquittal - Legality.  Anno. Cr. P. C.  S. 256  N. 4  5; S. 258  N. 4; S. 439  N. 12.  Nalin Chandra Banerjee for J.M. Banerjee - for Petnr.; Nalini Kumar Mukherjee - for Opposite Party.  Retrial Ordered .\"]\n","question_test = [\"name\"]\n","\n","encoded_test = tokenizer(context_test,question_test, padding=True, truncation=True)\n","print(encoded_test)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:22:05.845987Z","iopub.status.busy":"2024-01-01T06:22:05.845605Z","iopub.status.idle":"2024-01-01T06:22:05.859251Z","shell.execute_reply":"2024-01-01T06:22:05.858082Z","shell.execute_reply.started":"2024-01-01T06:22:05.845955Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<_TensorSliceDataset element_spec={'input_ids': TensorSpec(shape=(211,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(211,), dtype=tf.int32, name=None)}>\n"]}],"source":["train_dataset = tf.data.Dataset.from_tensor_slices((\n","    {key: encoded_test[key] for key in ['input_ids', 'attention_mask']}))\n","print(train_dataset)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:22:05.860786Z","iopub.status.busy":"2024-01-01T06:22:05.860450Z","iopub.status.idle":"2024-01-01T06:22:07.025646Z","shell.execute_reply":"2024-01-01T06:22:07.024811Z","shell.execute_reply.started":"2024-01-01T06:22:05.860759Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 1s/step\n"]}],"source":["outputs = model.predict(train_dataset)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-01T06:22:07.027146Z","iopub.status.busy":"2024-01-01T06:22:07.026861Z","iopub.status.idle":"2024-01-01T06:22:07.038259Z","shell.execute_reply":"2024-01-01T06:22:07.037175Z","shell.execute_reply.started":"2024-01-01T06:22:07.027121Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["58 89\n","Bepin Behari Maity - Complainant - Petnr v. Paban Sardar and other Accused Opposite Party\n"]}],"source":["start_logits, end_logits = outputs['start_logits'], outputs['end_logits']\n","start_index = tf.argmax(start_logits, axis=1).numpy()[0]\n","end_index = tf.argmax(end_logits, axis=1).numpy()[0] + 1 \n","print(start_index, end_index)\n","tokens = tokenizer.convert_ids_to_tokens(encoded_test['input_ids'][0])\n","answer_tokens = tokens[start_index:end_index]\n","answer = tokenizer.convert_tokens_to_string(answer_tokens)\n","print(answer)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4185608,"sourceId":7229462,"sourceType":"datasetVersion"},{"datasetId":4187292,"sourceId":7231618,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
